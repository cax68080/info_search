{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad253f23",
   "metadata": {},
   "source": [
    "# Chapter 3 特徴語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb01219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ch01_func as c1\n",
    "import ch02_func as c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3ad53",
   "metadata": {},
   "source": [
    "## 3.1 不要語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ab7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['京都', 'ちがう', '奈良', '魅力']\n"
     ]
    }
   ],
   "source": [
    "# 品詞を手掛かりとした不要語の除去\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.tokenfilter import ExtractAttributeFilter\n",
    "from janome.tokenfilter import POSStopFilter\n",
    "\n",
    "string = '京都とはちがう奈良の魅力！'\n",
    "stop_pos = ['助詞','助動詞','記号']\n",
    "analyzer = Analyzer(token_filters=[POSStopFilter(stop_pos),ExtractAttributeFilter('surface')])\n",
    "\n",
    "print(list(analyzer.analyze(string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca397cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['京都', '違う', '奈良', '魅力']\n"
     ]
    }
   ],
   "source": [
    "# 品詞を指定して抜き出す\n",
    "from janome.tokenfilter import POSKeepFilter\n",
    "\n",
    "string = '京都とは違う奈良の魅力。'\n",
    "keep_pos = ['名詞','動詞','形容詞','形容動詞']\n",
    "analyzer = Analyzer(token_filters=[POSKeepFilter(keep_pos),ExtractAttributeFilter('surface')])\n",
    "\n",
    "print(list(analyzer.analyze(string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_words関数(修正版)\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.tokenfilter import ExtractAttributeFilter\n",
    "from janome.tokenfilter import POSStopFilter\n",
    "from janome.tokenfilter import POSKeepFilter\n",
    "\n",
    "def get_words(string,keep_pos=None):\n",
    "    filters = []\n",
    "    if keep_pos is None:\n",
    "        filters.append(POSStopFilter(['記号']))\n",
    "    else:\n",
    "        filters.append(POSKeepFilter(keep_pos))\n",
    "    filters.append(ExtractAttributeFilter('surface'))\n",
    "    a = Analyzer(token_filters=filters)\n",
    "    return list(a.analyze(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c0251",
   "metadata": {},
   "source": [
    "## 3.2 TF・IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b1c158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春は私の好きな季節だけど花粉が怖い',\n",
      " '私は梅も桜も好きで，特に桜の香りが好きだ']\n"
     ]
    }
   ],
   "source": [
    "# サンプルデータの読み込み\n",
    "\n",
    "# 整形して表示するpprintのインポート\n",
    "from pprint import pprint\n",
    "\n",
    "D = ['irpb-files/data/ch03/1.txt','irpb-files/data/ch03/2.txt']\n",
    "texts = [c1.get_string_from_file(x) for x in D]\n",
    "pprint(texts,width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc86653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['春', '私', '好き', '季節', '花粉', '怖い'],\n",
      " ['私', '梅', '桜', '好き', '桜', '香り', '好き']]\n"
     ]
    }
   ],
   "source": [
    "# サンプルデータから指定した品詞を抽出する\n",
    "\n",
    "docs = [get_words(x,keep_pos=['名詞','動詞','形容詞','形容動詞']) for x in texts]\n",
    "pprint(docs,width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8216f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 好き\n",
      "1 季節\n",
      "2 怖い\n",
      "3 春\n",
      "4 私\n",
      "5 花粉\n",
      "6 桜\n",
      "7 梅\n",
      "8 香り\n"
     ]
    }
   ],
   "source": [
    "# corpora.Dictionaryで語にIDを付与する\n",
    "from gensim import corpora\n",
    "\n",
    "# docsからcorpora.Dictionaryオブジェクトを生成する\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "# 文字列とIDの組を順に表示する\n",
    "for k,v in dictionary.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74a3129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID=2の語は「怖い」\n",
      "「花粉」のIDは5\n"
     ]
    }
   ],
   "source": [
    "# IDから文字列、文字列からIDへの変換\n",
    "i = 2\n",
    "s = '花粉'\n",
    "\n",
    "# dictionary[i]でID iから文字列へ\n",
    "print('ID={}の語は「{}」'.format(i,dictionary[i]))\n",
    "# dictionary.token2id[s]で文字列sからIDへ\n",
    "print('「{}」のIDは{}'.format(s,dictionary.token2id[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4c73af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
      " [(0, 2), (4, 1), (6, 2), (7, 1), (8, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# bag-of-wordsの作成\n",
    "# Bag-of-words = id と出現頻度の組\n",
    "bows = [dictionary.doc2bow(d) for d in docs]\n",
    "pprint(bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610c4498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパスの構築を行うbuild_corpus関数\n",
    "def build_corpus(file_list,dic_file=None,corpus_file=None):\n",
    "    docs = []\n",
    "    for f in file_list:\n",
    "        text = c1.get_string_from_file(f)\n",
    "        words = get_words(text,keep_pos['名詞'])\n",
    "        docs.append(words)\n",
    "        # ファイル名を表示する\n",
    "        print(f)\n",
    "    dic = corpora.Dictionary(docs)\n",
    "    if not (dic_file is None):\n",
    "        dic.save(dic_file)\n",
    "    bows = [dic.doc2bow(d) for d in docs]\n",
    "    if not (corpus_file is None):\n",
    "        corpora.MmCorpus.serialize(corpus_file,bows)\n",
    "    return dic,bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812de02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書とコーパスを読み込むload_dictionary_and_corpus関数\n",
    "def bows_to_cfs(bows):\n",
    "    cfs = dict()\n",
    "    for b in bows:\n",
    "        for id,f in b:\n",
    "            if not id in cfs:\n",
    "                cfs[id] = 0 \n",
    "            cfs[id] += int(f)\n",
    "    return cfs\n",
    "\n",
    "def load_dictionary_and_corpus(dic_file,corpus_file):\n",
    "    dic = corpora.Dictionary.load(dic_file)\n",
    "    bows = list(corpora.MmCorpus(corpus_file))\n",
    "    if not hasattr(dic,'cfs'):\n",
    "        dic.cfs = bows_to_cfs(bows)\n",
    "    return dic,bows\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1c4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 2.0), (7, 1.0), (8, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "# TF・IDFの計算\n",
    "from gensim import models\n",
    "\n",
    "# 逆文書頻度(IDF)を計算する\n",
    "tfidf_model = models.TfidfModel(bows,normalize=False)\n",
    "# 2.txt(bows[1])のTF・IDFを計算する\n",
    "weights = tfidf_model[bows[1]]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8745219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパス作成のための関数\n",
    "def load_aozora_corpus():\n",
    "    return load_dictionary_and_corpus('irpb-files/data/aozora/aozora.dic','irpb-files/data/aozora/aozora.mm')\n",
    "\n",
    "def get_bows(texts,dic,allow_update=False):\n",
    "    bows = []\n",
    "    for text in texts:\n",
    "        words = get_words(text,keep_pos=['名詞'])\n",
    "        bow = dic.doc2bow(words,allow_update=allow_update)\n",
    "        bows.append(bow)\n",
    "    return bows\n",
    "\n",
    "import copy\n",
    "\n",
    "def add_to_corpus(texts,dic,bows,replicate=False):\n",
    "    if replicate:\n",
    "        dic = copy.copy(dic)\n",
    "        bows = copy.copy(bows)\n",
    "    texts_bows = get_bows(texts,dic,allow_update=True)\n",
    "    bows.extend(texts_bows)\n",
    "    return dic,bows,texts_bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63e46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(bows,dic,tfidf_model,surface=False,N=1000):\n",
    "    # TF・IDFを計算する\n",
    "    weights = tfidf_model[bows]\n",
    "    # TF・IDFの値を基準に降順にソート、最大でN個を抽出する\n",
    "    weights = [sorted(w,key=lambda x:x[1],reverse=True)[:N] for w in weights]\n",
    "    if surface:\n",
    "        return [[(dic[x[0]],x[1]) for x in w] for w in weights]\n",
    "    else:\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c126fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF・IDFの重みを計算するget_tfidfmodel_and_weights関数\n",
    "def translate_bows(bows,table):\n",
    "    return [[tuple([table[j[0]],j[1]]) for j in i if j[0] in table] for i in bows]\n",
    "\n",
    "def get_tfidfmodel_and_weights(texts,use_aozora=True,pos=['名詞']):\n",
    "    if use_aozora:\n",
    "        dic,bows = load_aozora_corpus()\n",
    "    else:\n",
    "        dic = corpora.Dictionary()\n",
    "        bows = []\n",
    "        \n",
    "    text_docs = [get_words(text,keep_pos=pos) for text in texts]\n",
    "    text_bows = [dic.doc2bow(d,allow_update=True) for d in text_docs]\n",
    "    bows.extend(text_bows)\n",
    "    \n",
    "    # textsに現れる語のidとtoken(表層形)のリストを作成する\n",
    "    text_ids = list(set([text_bows[i][j][0] for i in range(len(text_bows)) for j in range(len(text_bows[i]))]))\n",
    "    text_tokens = [dic[i] for i in text_ids]\n",
    "    \n",
    "    # text_bowsにない語を削除する\n",
    "    dic.filter_tokens(good_ids=text_ids)\n",
    "    # 削除前後のIDを対応付ける\n",
    "    # Y = id2id[X]として古いid Xから新しいid Yが得られるようになる\n",
    "    id2id = dict()\n",
    "    for i in range(len(text_ids)):\n",
    "        id2id[text_ids[i]] = dic.token2id[text_tokens[i]]\n",
    "        \n",
    "    # 語のIDが振りなおされたのに合わせてbowを変換する\n",
    "    bows = translate_bows(bows,id2id)\n",
    "    text_bows = translate_bows(text_bows,id2id)\n",
    "    \n",
    "    # TF・IDFモデルを作成する\n",
    "    tfidf_model = models.TfidfModel(bows,normalize=True)\n",
    "    # モデルに基づいて重みを計算する\n",
    "    text_weights = get_weights(text_bows,dic,tfidf_model)\n",
    "    \n",
    "    return tfidf_model,dic,text_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7122ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
